{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNKdfnkOIT4QpoUfceKt0FF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/you444Mo/Python-Projects/blob/main/GB656_Week_3_Assignment_(Baseball_GLM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseball Runs Predictive Model\n",
        "\n",
        "**Baseball Data Overview:**\n",
        "\n",
        "This data set with all games played in the Major League Baseball between the 2006 and 2016 season. Each row is a game with information on the home team, the visiting team, the season and the month of the game, etc.\n",
        "We are interested in predicting the number of runs scored by the home team (`h_score`) using all the information on the game (teams, record, etc.) but not the runs scored by the opponent (`v_score`)---since that will be only available after the game has been played."
      ],
      "metadata": {
        "id": "3Ke3BeWqtytT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RMcw6g7tsnO"
      },
      "outputs": [],
      "source": [
        "### Import needed packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import regex\n",
        "from datetime import datetime\n",
        "from itertools import zip_longest,product\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import PoissonRegressor\n",
        "from sklearn.linear_model import GammaRegressor\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Test for heteroscedasticity in OLS models\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pandas setting\n",
        "pd.set_option('display.max_columns', None) ### always show me all columns\n",
        "pd.set_option('display.max_rows', None) ### always show all rows\n",
        "pd.set_option('display.float_format', '{:.2f}'.format) ### Turn off scientific notation (format float)"
      ],
      "metadata": {
        "id": "LOYwzPnl_MWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data from GitHub Repo:"
      ],
      "metadata": {
        "id": "7eJBulaUv60o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danielbauer1979/MSDIA_PredictiveModelingAndMachineLearning.git"
      ],
      "metadata": {
        "id": "Grn3mfYTv3Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Read Baseball Game Historical Data into DF\n",
        "BBall_DF = pd.read_csv(\"/content/MSDIA_PredictiveModelingAndMachineLearning/GB886_III_9_BBallLogs.csv\")"
      ],
      "metadata": {
        "id": "E1hQE72cwGgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preliminary Data Analysis:"
      ],
      "metadata": {
        "id": "adBTpgkXwri1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Descriptive Analysis:"
      ],
      "metadata": {
        "id": "MEAsxtyOP56X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### View Dimensions of DF\n",
        "BBall_DF.shape"
      ],
      "metadata": {
        "id": "NjAwtLjgwowb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Datatypes\n",
        "BBall_DF.info()"
      ],
      "metadata": {
        "id": "pgV63y7CwzEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Notes:</u>**\n",
        "\n",
        "day_of_week, h_name, and v_name are our object datatype fields,<br> everything else is of int64"
      ],
      "metadata": {
        "id": "cTx1v0wdw4as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### View First Rows of data\n",
        "BBall_DF.head()"
      ],
      "metadata": {
        "id": "5D4PqTjNxCRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Descriptive Stats on Data\n",
        "BBall_DF.describe()"
      ],
      "metadata": {
        "id": "B-QuIF84xTB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Check for null values\n",
        "BBall_DF.isnull().sum()"
      ],
      "metadata": {
        "id": "YJyRWzTbSQ6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Total # of counts of each field variant within each obj variable\n",
        "obj_data = BBall_DF.select_dtypes(include = ['object'])\n",
        "\n",
        "for field in obj_data:\n",
        "  print(BBall_DF[field].value_counts())"
      ],
      "metadata": {
        "id": "5iEb9liMFcML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Distriubtion of the h_score Field\n",
        "BBall_DF['h_score'].value_counts()"
      ],
      "metadata": {
        "id": "B5H1XbyG7Xhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Visual Analysis:**"
      ],
      "metadata": {
        "id": "xVIW9RvIIXET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**View Various Relationships between h_score and other variables in dataset:**"
      ],
      "metadata": {
        "id": "MIVECkcOJfUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Variable Lists\n",
        "x = [i for i in BBall_DF if i not in ['h_score','v_score','day_of_week','h_name','v_name']] ### Pull Relevant non object type x variables"
      ],
      "metadata": {
        "id": "z-FHDsF4IanS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Distributions of a X Vars (Sans Object Types)\n",
        "for xvar in x:\n",
        "  print()\n",
        "\n",
        "  sns.histplot(\n",
        "      data = BBall_DF,\n",
        "      x = f\"{xvar}\"\n",
        "  )\n",
        "\n",
        "  plt.title(f\"Distribution of {xvar}\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "HtbsxIgLJ3l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "A bulk of the games seem to be occuring on either of the 1st or 30th of each given month.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2R2lMzlcMLbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**View how values of Yi (h_score) are distributed:**"
      ],
      "metadata": {
        "id": "WNfeBsv36_rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### View Distribtion of Y Var (Total Runs scored by Home Team)\n",
        "plt.hist(BBall_DF['h_score'])\n",
        "plt.title(\"Distibution of h_score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fGA-XOrMOUl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Distribtion of Y Var (Total Runs scored by Home Team) (View with skinnier bars)\n",
        "sns.histplot(\n",
        "    data = BBall_DF,\n",
        "    x = 'h_score',\n",
        ")\n",
        "\n",
        "plt.title(\"Distibution of h_score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9vT5hrA_3Phj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Notes:</u>**\n",
        "\n",
        "Judging from the above chart, the h_score variable is discrete, which would ultimatley make it fall under the realm of a possion distribution, albeat 1 that is skewed to the right."
      ],
      "metadata": {
        "id": "sz5sH16B3hlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modeling (Prep/Fit):**"
      ],
      "metadata": {
        "id": "A2ySmOj1FJzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Variable Prep:**"
      ],
      "metadata": {
        "id": "ceyJsZwBP-3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Set Y Var\n",
        "Y_Freq = BBall_DF['h_score']\n",
        "\n",
        "### Set X Var\n",
        "X = BBall_DF.select_dtypes(include = ['int64']).drop(columns = ['h_score','v_score']) ### Drop Categoricals, v_score, h_score variable"
      ],
      "metadata": {
        "id": "_sC5vvApO_Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Freq.head()"
      ],
      "metadata": {
        "id": "EY9Ra00zQqEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "ITFIs2IRQsrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert categorical variables to dummy variables\n",
        "dummy_fields = pd.get_dummies(\n",
        "    obj_data,\n",
        "    dtype = int, ### Set Dummy Variable Data Type to Integer\n",
        "    drop_first = True ### Drop First of each dummy variable to avoid dummy variable trap\n",
        ")\n",
        "\n",
        "### View Dummy Fields\n",
        "dummy_fields.head()"
      ],
      "metadata": {
        "id": "SMbNbmppFJXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add Back Dummy Variables to original Dataframe\n",
        "X_W_Dummies = pd.concat([X,dummy_fields], axis = 1) ### axis = 0: row-wise concat, axis = 1: column-wise concat\n",
        "\n",
        "X_W_Dummies.head()"
      ],
      "metadata": {
        "id": "_BItrlEGO4rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Check Shape of new X Var DF\n",
        "X_W_Dummies.shape"
      ],
      "metadata": {
        "id": "1snHp_sGSpX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add Constant To Design Matrix\n",
        "X_W_DummiesWConstant = sm.add_constant(X_W_Dummies)\n",
        "\n",
        "X_W_DummiesWConstant"
      ],
      "metadata": {
        "id": "VOTCvRroi4Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Fit Model:**"
      ],
      "metadata": {
        "id": "TKWjO3H_Q4ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Fit a Poission Regression on the data\n",
        "# Create a PoissonRegressor Object\n",
        "TotalRunsFreqModel = PoissonRegressor(max_iter = 10000)\n",
        "# Fit model\n",
        "TotalRunsFreqModel.fit(X_W_DummiesWConstant,Y_Freq)\n",
        "# Predict based on X Variables\n",
        "preds_freq = TotalRunsFreqModel.predict(X_W_DummiesWConstant)\n",
        "# Show Correlations between Predictions and Outcomes\n",
        "np.corrcoef(preds_freq,Y_Freq) ### about 12.62% Correlation Between Prediction and Outcomes"
      ],
      "metadata": {
        "id": "bxS7j--CRNQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generation of Model Summary for Further Analysis\n",
        "link_p = sm.genmod.families.links.log  # use a log link\n",
        "model_poisson = sm.GLM(Y_Freq, X_W_DummiesWConstant.astype(float), family=sm.families.Poisson(link_p())).fit()\n",
        "print(model_poisson.summary())"
      ],
      "metadata": {
        "id": "eYjiiYRujX7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Inital Model Notes:</u>**\n",
        "\n",
        "There was an initial \"Convergence error\" when attempting to fit the model, so I had to increase the max interations threshold to 10000 to allow the algorithm to find an optimal solution.\n",
        "\n",
        "The correlation coefficient between the predicted and actual Y Frequencies sits at about **12.62%.**\n",
        "\n",
        "When looking at the model summary. We see that the Pseudo R-squared sits at 0.06333, indicating that only 6.3% of the variance is being explained by the model. The deviance score (an indicator of goodness of fit) sits at 55237 (less is better). This indicates that the model may not fit well on the data. The Chi-squared value of 5.31e+04 indicates the values for Y may be widley dispersed (variance > mean).\n",
        "<br>\n",
        "<br>\n",
        "**<u>Interpretation of Beta Coefficients</u>:**\n",
        "\n",
        "Beta Coeff for h_wins = 0.0019.\n",
        "\n",
        "If we take e^0.0019 (plugged beta into log link function), we get 1.0019.\n",
        "* 1 - 1.0019 = 0.0019.\n",
        "\n",
        "We are saying here that for every unit change in h_wins, our predicted h_score increases by about 0.19%."
      ],
      "metadata": {
        "id": "Awdo6-Ptby8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Plot of Predicited Values vs Actuals:**"
      ],
      "metadata": {
        "id": "ARpr24ODc9kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Plotting Predicted Freqs vs Actual Y Freqs\n",
        "plt.scatter(Y_Freq,preds_freq)\n",
        "plt.xlabel('Y_Freq')\n",
        "plt.ylabel('Y_Preds_Freq')\n",
        "plt.title(\"Y vs Predicted Y\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Mex-GzBdB1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inital Observations**\n",
        "\n",
        "Generally, the model seems to be underpredicting the total number of runs, especially as we move further and further to the left of the chart to higher Actual Frequencies. When we hit 20 for actual frequency of Runs, the model is predicting anywhere from 4.2 to 5.3 runs. It can be noted too that as we move to higher frequency levels, the predicted bands tend to get narrower, indicating that the model is more consistently assigning a predicted value for total runs (albiet still underpredicting)."
      ],
      "metadata": {
        "id": "wC9t6DrziwNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Further Validation:**"
      ],
      "metadata": {
        "id": "x6if0-5ckyRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean of Ys: {np.mean(Y_Freq)}\")"
      ],
      "metadata": {
        "id": "niJJ8H3diJz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Variance of Ys: {np.var(Y_Freq)}\")"
      ],
      "metadata": {
        "id": "244Lr_MViNNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Note:</u>**\n",
        "\n",
        "Since the Variance of the Ys of this dataset exceed that of it's mean, this indicates overdispersion of the data, which can lead to potentially innacurate predictions. This validates the output for Chi-Squared in the model summary."
      ],
      "metadata": {
        "id": "Z0c2KKT3k14o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Fit Model (Scaled Version):**\n",
        "\n",
        "Will now perform standard scaling on the design matrix to see if this imporves the accuracy/fit of the model improves.\n",
        "\n",
        "Standard scaling involves showing the normally distributed values (z-scores) of each of our predictor variables (mean of 0, stdev of 1), which accounts for cases like where we have a year field that it's in the 2000s vs having dummy variable fields (1/0). The model in that case may assign more inportance(higher weights) to the year field simply because it's a much large number than our dummy fields. Scaling puts both these fields on the same scale, allowing for more fair weighting."
      ],
      "metadata": {
        "id": "IgxDTeJupb1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Set Scaler Object\n",
        "Scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "9IBlrXlglgGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Scale Design Matrix\n",
        "X_W_Dummies_Scaled = Scaler.fit_transform(X_W_Dummies)"
      ],
      "metadata": {
        "id": "vZoJOjz5p9-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Scale Design Matrix\n",
        "X_W_Dummies_Scaled"
      ],
      "metadata": {
        "id": "5sfM45TVqOGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Insert Back into a dataframe\n",
        "X_W_Dummies_Scaled_DF = pd.DataFrame(X_W_Dummies_Scaled, columns = X_W_Dummies.columns)"
      ],
      "metadata": {
        "id": "RpPLk3e0qYKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add Constant\n",
        "X_W_Dummies_Scaled_WConstant = sm.add_constant(X_W_Dummies_Scaled_DF)\n",
        "\n",
        "X_W_Dummies_Scaled_WConstant.head()"
      ],
      "metadata": {
        "id": "ESh3ts3KqkFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Fit a Scaled Poission Regression on the data\n",
        "# Create a PoissonRegressor Object\n",
        "TotalRunsFreqModel_Scaled = PoissonRegressor()\n",
        "# Fit model\n",
        "TotalRunsFreqModel_Scaled.fit(X_W_Dummies_Scaled_WConstant,Y_Freq)\n",
        "# Predict based on X Variables\n",
        "preds_freq_Scaled = TotalRunsFreqModel_Scaled.predict(X_W_Dummies_Scaled_WConstant)\n",
        "# Show Correlations between Predictions and Outcomes\n",
        "np.corrcoef(preds_freq_Scaled,Y_Freq) ### about 17.30% Correlation Between Prediction and Outcomes"
      ],
      "metadata": {
        "id": "0CuDzacZr19v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generation of Model Summary for Further Analysis\n",
        "link_p = sm.genmod.families.links.log  # use a log link\n",
        "model_poisson_scaled = sm.GLM(Y_Freq, X_W_Dummies_Scaled_WConstant.astype(float), family=sm.families.Poisson(link_p())).fit()\n",
        "print(model_poisson_scaled.summary())"
      ],
      "metadata": {
        "id": "1A9Awy1wsF5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>**How to Interpret:**</u>\n",
        "\n",
        "Beta Coeff for h_wins = 0.0469.\n",
        "\n",
        "If we take e^0.0469 (plugged beta into log link function), we get 0.952.\n",
        "* 1 - 0.952 = 4.8.\n",
        "\n",
        "We are saying here that for 1 standard deviation change in the variable h_wins, our predict h_score increases by about 4.8%"
      ],
      "metadata": {
        "id": "PJ7jTPLByKUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Scaled Plot of Predicted Versus Actuals:**"
      ],
      "metadata": {
        "id": "xqn3VUuovc3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Plotting Predicted Freqs vs Actual Y Freqs\n",
        "plt.scatter(Y_Freq,preds_freq_Scaled)\n",
        "plt.xlabel('Y_Freq')\n",
        "plt.ylabel('preds_freq_Scaled')\n",
        "plt.title(\"Y vs Scaled Predicted Y\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FZLRyJGjusZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Notes:</u>**\n",
        "\n",
        "* The scaled model did not produce a \"convergence error\" when being fit, so no max iterations adjustment was needed.\n",
        "\n",
        "\n",
        "* The Scaled Model yields an imporved correlation coefficient between y_predicted and y_acutal (17.3%)\n",
        "\n",
        "* When looking at the regression summary, we actually see that the summary statistics such as the chi-squared and the deviance show the same values as in the unscaled model.\n",
        "\n",
        "* When plotting the predicited results of our Scaled Model vs Actual Frequencies, we do see still see general underpredicting of total runs, but we do notice that the predicited values for y are slightly more condensed then our unscaled model as we move further to the right of the chart."
      ],
      "metadata": {
        "id": "In-OE5AUsxpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predicting Total Runs in a Game:**\n",
        "\n",
        "Will do so using the uscaled and scaled models to see if there are any significant differences between the 2"
      ],
      "metadata": {
        "id": "ZxJwGJ7AwSLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Read Data into Dataframe\n",
        "Astros_DF = pd.read_csv('/content/AstrosSeason2017.csv', encoding='cp1252')"
      ],
      "metadata": {
        "id": "hTMJD-xPwXF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View DF\n",
        "Astros_DF.head()"
      ],
      "metadata": {
        "id": "_uib6YlT1m6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Keep only relavent Rows\n",
        "Astros_DF_Modeling = Astros_DF.copy()\n",
        "\n",
        "Astros_DF_Modeling.drop(columns = ['Unnamed: 2', 'Unnamed: 4', 'W/L','GB','Win','Loss','Save','Time','D/N','Attendance','Streak','Orig. Scheduled','Inn','Rank','R','RA','cLI'], inplace = True)\n",
        "\n",
        "Astros_DF_Modeling.head()"
      ],
      "metadata": {
        "id": "bY7AQnrjsIBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add Year and Team Name Field\n",
        "Astros_DF_Modeling['Year'] = 2017\n",
        "\n",
        "Astros_DF_Modeling.head()"
      ],
      "metadata": {
        "id": "3nm5yy1ftY8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Split Win/Loss Field\n",
        "Astros_DF_Modeling[['W','L']] = Astros_DF_Modeling['W-L'].str.split('-',expand = True)\n",
        "### Drop Old W-L Field\n",
        "Astros_DF_Modeling.drop(columns = ['W-L'], inplace = True)"
      ],
      "metadata": {
        "id": "uIZa_8h52qGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the Date column first: remove leading/trailing spaces\n",
        "Astros_DF_Modeling['Date'] = Astros_DF_Modeling['Date'].str.strip()\n",
        "\n",
        "# Function to extract month and day\n",
        "def extract_month_day(date_str):\n",
        "    # Remove any extra non-date characters if needed\n",
        "    date_str = date_str.split('(')[0].strip()  # removes anything after '('\n",
        "    dt = datetime.strptime(date_str, '%A %b %d')\n",
        "    return pd.Series([dt.month, dt.day])\n",
        "\n",
        "# Apply function\n",
        "Astros_DF_Modeling[['Month', 'Day']] = Astros_DF_Modeling['Date'].apply(extract_month_day)\n",
        "\n",
        "# View DF\n",
        "Astros_DF_Modeling.head()"
      ],
      "metadata": {
        "id": "V5eqSfVVuCYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a \"day_of_week\" Field\n",
        "#Clean out any parentheses or trailing spaces\n",
        "Astros_DF_Modeling['Date_clean'] = Astros_DF_Modeling['Date'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
        "\n",
        "#Add the year\n",
        "Astros_DF_Modeling['Date_full'] = Astros_DF_Modeling['Date_clean'] + ' 2017'\n",
        "\n",
        "#Parse into datetime (let pandas infer format)\n",
        "Astros_DF_Modeling['Date_parsed'] = pd.to_datetime(Astros_DF_Modeling['Date_full'], errors='coerce')\n",
        "\n",
        "#Create an Entry Map\n",
        "day_map = {\n",
        "    'Monday': 'Mon',\n",
        "    'Tuesday': 'Tue',\n",
        "    'Wednesday': 'Wed',\n",
        "    'Thursday': 'Thu',\n",
        "    'Friday': 'Fri',\n",
        "    'Saturday': 'Sat',\n",
        "    'Sunday': 'Sun'\n",
        "}\n",
        "\n",
        "Astros_DF_Modeling['day_of_week'] = Astros_DF_Modeling['Date_parsed'].dt.day_name().map(day_map)\n",
        "\n",
        "Astros_DF_Modeling[['Date', 'day_of_week']].head()"
      ],
      "metadata": {
        "id": "819zlJoD5sB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Old Date Field\n",
        "Astros_DF_Modeling.drop(columns = ['Date','Date_full','Date_clean','Date_parsed'], inplace = True)"
      ],
      "metadata": {
        "id": "x12zuArjvK1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View DF\n",
        "Astros_DF_Modeling.head()"
      ],
      "metadata": {
        "id": "0IzPK9XLvyNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column Mover Function\n",
        "def ColumnMover (df,colname, position):\n",
        "  col = df.pop(colname)\n",
        "  df.insert(position, colname, col)"
      ],
      "metadata": {
        "id": "DPJqAZESwUo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a v_game_number field based off home game number\n",
        "Astros_DF_Modeling['v_game_number'] = Astros_DF_Modeling['Gm#']"
      ],
      "metadata": {
        "id": "GNjueFzk2T0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Move Columns to appropriate positions\n",
        "ColumnMover(Astros_DF_Modeling,'Year',0)\n",
        "ColumnMover(Astros_DF_Modeling,'Month',1)\n",
        "ColumnMover(Astros_DF_Modeling,'Day',2)\n",
        "ColumnMover(Astros_DF_Modeling,'Gm#',3)\n",
        "ColumnMover(Astros_DF_Modeling,'W',4)\n",
        "ColumnMover(Astros_DF_Modeling,'v_game_number',5)\n",
        "ColumnMover(Astros_DF_Modeling,'L',6)\n",
        "ColumnMover(Astros_DF_Modeling,'day_of_week',7)"
      ],
      "metadata": {
        "id": "1pNGY74r4eGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Rename Fields Where Appropriate\n",
        "Astros_DF_Modeling.rename(\n",
        "    columns= {\n",
        "        'Gm#' : 'h_game_number',\n",
        "        'W': 'h_wins',\n",
        "        'L': 'v_wins',\n",
        "        'Tm': 'h_name',\n",
        "        'Opp': 'v_name'\n",
        "    }, inplace = True\n",
        ")"
      ],
      "metadata": {
        "id": "HmPdEYob4KDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View DF\n",
        "Astros_DF_Modeling.head()"
      ],
      "metadata": {
        "id": "Sq4iOK_75AzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Data Types\n",
        "Astros_DF_Modeling.info()"
      ],
      "metadata": {
        "id": "v44juLTE8fqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert h_wins and v_wins to int64\n",
        "Astros_DF_Modeling['h_wins'] = Astros_DF_Modeling['h_wins'].astype('int64')\n",
        "Astros_DF_Modeling['v_wins'] = Astros_DF_Modeling['v_wins'].astype('int64')"
      ],
      "metadata": {
        "id": "frmBbfvM8yDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create Dummy Vars\n",
        "Obj_Variables = Astros_DF_Modeling.select_dtypes(include = 'object')\n",
        "\n",
        "Astros_Dummy_Vars = pd.get_dummies(\n",
        "    Obj_Variables,\n",
        "    dtype = int,\n",
        "    drop_first = True\n",
        ")\n",
        "\n",
        "Astros_Dummy_Vars.head()"
      ],
      "metadata": {
        "id": "NxrBe7Nt7plc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Drop Categ Fields from Modeling DF\n",
        "Astros_DF_Modeling.drop(columns = ['day_of_week','h_name','v_name'], inplace = True)\n",
        "\n",
        "### Merge Dummies Back with Modeling DF\n",
        "Astros_DF_Modeling_wDummies = pd.concat([Astros_DF_Modeling,Astros_Dummy_Vars], axis = 1)"
      ],
      "metadata": {
        "id": "1JFLmDpk9oHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add Constant\n",
        "Astros_DF_Modeling_wDummies_Const = sm.add_constant(Astros_DF_Modeling_wDummies, has_constant='add')"
      ],
      "metadata": {
        "id": "1eWZ6yWi-T6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Modeling DF\n",
        "Astros_DF_Modeling_wDummies_Const.head()"
      ],
      "metadata": {
        "id": "Yve6NI4VAcvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Note:</u>**\n",
        "\n",
        "In order to utilize the fitted model, we need to ensure that we have the same amount of fields in this test data set that we used to train the model on."
      ],
      "metadata": {
        "id": "SqM5PTx7I_l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Choose Specific Game from testing dataset\n",
        "Chosen_Game = Astros_DF_Modeling_wDummies_Const.head(1)\n",
        "\n",
        "Chosen_Game ### Hous Vs Seahawks"
      ],
      "metadata": {
        "id": "jwq8NQXpJvM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### List out all matchups from original dataset\n",
        "field_list_model =X_W_DummiesWConstant.columns.to_list()\n",
        "\n",
        "Team_Matchup_lst = [i for i in field_list_model if i.startswith('v_name') or i.startswith('h_name')]\n",
        "\n",
        "Team_Matchup_lst"
      ],
      "metadata": {
        "id": "1aVTU2-ED6rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Store In a Dataframe\n",
        "All_H_and_V_Df = pd.DataFrame(columns = Team_Matchup_lst)"
      ],
      "metadata": {
        "id": "5GNkRoN9E-_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new row with all zeros\n",
        "new_row = pd.Series(0, index=All_H_and_V_Df.columns)\n",
        "\n",
        "# Set matchup teams to 1\n",
        "new_row['h_name_HOU'] = 1\n",
        "new_row['v_name_SEA'] = 1\n",
        "\n",
        "# Add the new row to the DataFrame\n",
        "All_H_and_V_Df.loc[len(All_H_and_V_Df)] = new_row\n",
        "\n",
        "# All_H_and_V_Df"
      ],
      "metadata": {
        "id": "u66hENsyG2Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Drop All Matchup info from chosen df\n",
        "Chosen_Game_Dropped = Chosen_Game.drop(columns = [i for i in Chosen_Game if i.startswith('v_name') or i.startswith('h_name')])\n",
        "\n",
        "Chosen_Game_Dropped"
      ],
      "metadata": {
        "id": "ScTqBjNoKY-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Merge stats from testing dataset with full matchup list\n",
        "Chosen_Game_Final = pd.concat([Chosen_Game_Dropped,All_H_and_V_Df], axis = 1)"
      ],
      "metadata": {
        "id": "DvEkNxeMID3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### View Final Game DF Stats for Chosen Game\n",
        "Chosen_Game_Final"
      ],
      "metadata": {
        "id": "cT7gGlrBISfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Unscaled Result:**"
      ],
      "metadata": {
        "id": "u3UrC_wuMSci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Run Unscaled Model\n",
        "Predicted_Total_Runs = TotalRunsFreqModel.predict(Chosen_Game_Final)\n",
        "\n",
        "print(f\"Predicted Runs: {Predicted_Total_Runs}\")"
      ],
      "metadata": {
        "id": "oNNknldwA2Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Compare to actual Result for this game\n",
        "Actual_Runs = Astros_DF.iloc[0]['R']\n",
        "\n",
        "print(f\"Actual Runs: {Actual_Runs}\")"
      ],
      "metadata": {
        "id": "MZxWUtXLLKFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unscaled Model predicts a total runs amount of 4.09 for the Astros vs the Seattle. The actual result was 3."
      ],
      "metadata": {
        "id": "bChyvL5cL-Py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Scaled Result:**"
      ],
      "metadata": {
        "id": "5HquTKlTMU6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Scale Design Matrix\n",
        "Chosen_Game_Final_Scaled = Scaler.fit_transform(Chosen_Game_Final)"
      ],
      "metadata": {
        "id": "Y9joWXKZMsja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Run Scaled Model\n",
        "Predicted_Total_Runs_Scaled = TotalRunsFreqModel_Scaled.predict(Chosen_Game_Final_Scaled)\n",
        "\n",
        "print(f\"Predicted Runs (Scaled): {Predicted_Total_Runs_Scaled}\")"
      ],
      "metadata": {
        "id": "6gvy3tAyL6OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly Enough, the scaled model provided a less accurate result, prediciting 4.5 runs."
      ],
      "metadata": {
        "id": "dqRMzWaxNJL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u>Main conclusion</u>:\n",
        "\n",
        "The Models did a commendable job, but in the end..... Predicting stuff to happen in sports is hard...... (:"
      ],
      "metadata": {
        "id": "jPgB88rjNRQB"
      }
    }
  ]
}